\documentclass[11pt]{article}
\usepackage{enumitem}
\usepackage{listings}
\usepackage[listings]{tcolorbox}
\usepackage{tikz}
\usepackage{url}

%\usepackage{algorithm2e}
\usetikzlibrary{arrows,automata,shapes}
\tikzstyle{block} = [rectangle, draw, fill=blue!20, 
    text width=5em, text centered, rounded corners, minimum height=2em]
\tikzstyle{bt} = [rectangle, draw, fill=blue!20, 
    text width=4em, text centered, rounded corners, minimum height=2em]

\lstset{ %
language=Java,
basicstyle=\ttfamily,commentstyle=\itshape,showstringspaces=false,breaklines=true,numbers=left}
\newtcbinputlisting{\codelisting}[3][]{
    extrude left by=1em,
    extrude right by=2em,
    listing file={#3},
    fonttitle=\bfseries,
    listing options={basicstyle=\ttfamily\footnotesize,numbers=left,language=Java,#1},
    listing only,
    hbox,
}
\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, 
do, else, case, break},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]''
}


\newtheorem{defn}{Definition}
\newtheorem{crit}{Criterion}

\newcommand{\handout}[5]{
  \noindent
  \begin{center}
  \framebox{
    \vbox{
      \hbox to 5.78in { {\bf Software Testing, Quality Assurance and Maintenance } \hfill #2 }
      \vspace{4mm}
      \hbox to 5.78in { {\Large \hfill #5  \hfill} }
      \vspace{2mm}
      \hbox to 5.78in { {\em #3 \hfill #4} }
    }
  }
  \end{center}
  \vspace*{4mm}
}

\newcommand{\lecture}[4]{\handout{#1}{#2}{#3}{#4}{Lecture #1}}
\topmargin 0pt
\advance \topmargin by -\headheight
\advance \topmargin by -\headsep
\textheight 8.9in
\oddsidemargin 0pt
\evensidemargin \oddsidemargin
\marginparwidth 0.5in
\textwidth 6.5in

\parindent 0in
\parskip 1.5ex
%\renewcommand{\baselinestretch}{1.25}

\begin{document}

\lecture{7 --- January 26, 2026}{Winter 2026}{Patrick Lam}{version 1}

We are now going to spend 3 weeks on fuzzing. This is a technique that
works well in practice today, and is particularly useful for
discovering security bugs, in conjunction with sanitizers.  It tends
to find bugs caused, for instance, by a lack of sufficient input
validation.

\section*{Introduction: Fuzzing}

Consider the following JavaScript code\footnote{\url{http://webkit.sed.hu/blog/20130710/fuzzinator-mutation-and-generation-based-browser-fuzzer}}.
\begin{lstlisting}[language=JavaScript]
function test() {
    var f = function g() {
        if (this != 10) f();
    };
    var a = f();
}
test();
\end{lstlisting}
Turns out that it can crash WebKit (\url{https://bugs.webkit.org/show_bug.cgi?id=116853}).
Plus, it was automatically generated by the Fuzzinator tool, based on a grammar for JavaScript.


\paragraph{Origin Story.} It starts with line noise.
In 1988, Prof. Barton Miller was using a 1200-baud dialup modem to
communicate with a UNIX system on a dark and stormy night.  He found
that the random characters inserted by the noisy line would cause his
UNIX utilities to crash. He then challenged graduate students in his
Advanced Operating Systems class to write a fuzzer---a program which
would generate (unstructured ASCII) random inputs for other programs.
The result: the students observed that 25\%-33\% of UNIX utilties
crashed on random inputs\footnote{\url{http://pages.cs.wisc.edu/~bart/fuzz/Foreword1.html}}.
% footnote: fuzzing book foreword

(That was not the earliest known example of fuzz testing. Apple
implemented ``The Monkey'' in 1983\footnote{\url{http://www.folklore.org/StoryView.py?story=Monkey_Lives.txt}}
to generate random events for
MacPaint and MacWrite. It found lots of bugs. The limiting factor was
that eventually the monkey would hit the Quit command.  The solution
was to introduce a system flag, ``MonkeyLives'', and have MacPaint and
MacWrite ignore the quit command if MonkeyLives was true.)
% footnote: folklore.org

\paragraph{Experience Report: Fuzzinator.} The author of Fuzzinator, a fuzzing tool, wrote on her blog\footnote{\url{http://webkit.sed.hu/blog/20141023/fuzzinator-reloaded}}:

\begin{quote}
  More than a year ago, when I started fuzzing, I was mostly focusing on mutation-based fuzzer technologies since they were easy to build and pretty effective. Having a nice error-prone test suite (e.g. LayoutTests) was the warrant for fresh new bugs. At least for a while.\\[1em]

  As expected, the test generator based on the knowledge extracted from a finite set of test cases reached the edge of its possibilities after some time and didn't generate essentially new test cases anymore.\\[1em]

  At this point, a fuzzer girl can reload her gun with new input test sets and will probably find new bugs. This works a few times but she will soon find herself in a loop testing the common code paths and running into the same bugs again and again.
\end{quote}

\paragraph{How Fuzzing Works.} 
Two kinds of fuzzing: \emph{mutation-based} and
\emph{generation-based}. Mutation-based testing starts with
existing test cases and randomly modifies them to explore new behaviours.
Generation-based testing starts with a grammar and generates
inputs that match the grammar.

In fuzzing, you feed generated inputs to the program and find
crashes, or assertion failures, or you run the program under a dynamic
analysis tool such as Valgrind and observe runtime errors (using implicit oracles).

\paragraph{The Simplest Thing That Could Possibly Work.}
Consider generation-based testing for HTML5.  The simplest grammar---actually a regular
expression---that could possibly
work\footnote{\url{http://trevorjim.com/a-grammar-for-html5/}} is {\tt
  .*}, where {\tt .} is ``any character'' and {\tt *} means ``0 or
more''. Indeed, that grammar found the following WebKit assertion failure:
\url{https://bugs.webkit.org/show_bug.cgi?id=132179}.

The process is as described previously. Take the regular expression
and generate random strings from it.  Feed them to the browser and see
what happens. Find an assertion failure/crash.

\subsection*{Worked Example: Fuzzing UNIX utility bc}
The next bit, until we talk about Address Sanitizer, is from \url{https://www.fuzzingbook.org/html/Fuzzer.html}.

We can demonstrate ``any character''-style generation with the UNIX command {\tt bc}. These days,
you're unlikely to find anything that way---especially since the \texttt{bc} we're working with is a modern reimplementation, and its author believes in fuzzing. But we can still use it for demonstration purposes. Here is some code that generates some number (default 100) of ASCII characters (between 32 and 64):

\lstinputlisting[language=Python]{code/L07/fuzzer.py}

We can write it to a temp file. As an example of using assertions, let's read it back and check that we got back the same thing we wrote. This depends on having the \texttt{fuzzer()} function, defined above, available. This example does not yet call \texttt{bc}.

\lstinputlisting[language=Python]{code/L07/roundtrip_to_disk.py}
(By the way, this one-step call to \texttt{mkdtemp()} is the safe way to create a temporary directory, with \texttt{mkdtemp()}\footnote{\url{https://cwe.mitre.org/data/definitions/377.html}}. If you create a temporary file or directory in two steps---requesting a name and then creating a file with that name---that can be exploited by an attacker in another process. The higher-level way to create a temp file is \texttt{tempfile.TemporaryFile}.)

We can run a subprocess in Python, e.g. \texttt{bc}, like so:
\lstinputlisting[language=Python]{code/L07/run_bc_once.py}
This calls \texttt{bc} with input ``2 + 2''. We expect output ``4''.

And we can run \texttt{bc} repeatedly, with output from \texttt{fuzzer()}. This is a pretty small-scale fuzzing campaign.
\lstinputlisting[language=Python]{code/L07/fuzzing_campaign.py}

We can inspect the outcome in various ways:
\lstinputlisting[language=Python]{code/L07/run_fuzzing_campaign.py}
We can see that almost all runs result in error messages (about 95\%) and there are almost no non-empty outputs from non-error runs.

\paragraph{Causes of problems.} Programs should never crash; ideally they
might fail in a controlled way (with an error message), and best yet,
they produce the right answer. Originally, Miller and his students
did find a lot of crashes. C doesn't help. Let's talk about crashes some more.

Consider the following C code and the input ``Wednesday'':
\begin{lstlisting}[language=C]
  char weekday[9]; // 8 characters + trailing '\0' terminator
  strcpy (weekday, input);
\end{lstlisting}
What happens? How bad is it? It turns out that \emph{buffer overflows}
are attack vectors, and can be used by attackers to gain control
of the executing user's account.

Python doesn't really have buffer overflows, because it checks buffer
length and fails fast instead. Rust also has fewer buffer overflows
than C++, according to Google\footnote{\url{https://security.googleblog.com/2025/11/rust-in-android-move-fast-fix-things.html}}. (There still can be
buffer overflows in unsafe Rust.)

Another bad thing in C comes from not doing error checks.
\begin{lstlisting}[language=C]
  while (getchar() != ' ');
\end{lstlisting}
If there is an end-of-file on standard input, then \texttt{getchar()}
returns the value \texttt{EOF}, which is never a space. This
implies an \emph{infinite loop}. This sort of infinite loop is also
possible in other languages, and one can use a timeout to guess
whether or not the code is looping.

Unexpected unsanitized inputs can also cause havoc:
\begin{lstlisting}[language=C]
char *read_input() {
    size_t size = read_buffer_size();
    char *buffer = (char *)malloc(size);
    // fill buffer
    return (buffer);
}
\end{lstlisting}
The function \texttt{read\_buffer\_size()} might return
something that is \emph{not a valid size}: the number of requested
bytes may be too big; or it might be smaller than the number
of bytes that actually get filled (another buffer overflow).
The Fuzzing Book talks about \texttt{size} being negative,
but that's not allowed by spec, since \texttt{size\_t} is an unsigned type.

\paragraph{Finding problems.} As I've explicitly said, crashes
are always bad. I alluded to sanitizers above also. Let's talk
about them in more detail.

Here is a C program that can trigger a buffer overflow on demand.

\lstinputlisting[language=C]{code/L07/buffer-overflow-on-demand.c}

(How nice of it to clean up memory; it's fine to rely on \texttt{buf}
being freed upon exit, but less tidy, and potentially problematic
if it was instead a function that could be called arbitrarily many times.)

If you compile it like this:
\begin{verbatim}
 clang -fsanitize=address -g buffer-overflow.c
\end{verbatim}
and you invoke it with a sufficiently large argument, then you'll
get an AddressSanitizer error telling you the program did something bad.

Combine this with fuzzing and you can detect some memory errors
in programs. The program will run like $2\times$ slower with
AddressSanitizer. Another option is valgrind, which is more
picky but also runs like $100\times$ slower.

\paragraph{A problem found using AddressSanitizer: Heartbleed.}

xkcd has a good explainer (in pictures): \url{https://xkcd.com/1354/}

In words: the OpenSSL implementation allowed the client to say
how many bytes it was supposed to return when requesting
a heartbeat. The number of bytes asked-for could exceed the
number of bytes specified, thus returning bytes to the client
(or server) that it shouldn't be allowed to see. There is also a good
Wikipedia page: \url{https://en.wikipedia.org/wiki/Heartbleed}.

We're talking about this now because researchers at Google and Codenomicon
discovered Heartbleed using a memory sanitizer, feeding fuzzed inputs
to OpenSSL. The sanitizer found the illegal accesses, which then were
easy enough to fix (although when something like this turns out, it's
important to follow responsible disclosure practices.)

\paragraph{Fuzzing Summary.} Fuzzing is a useful technique for finding
interesting test cases. It works best at interfaces between components.
Advantages: it runs automatically and really works. Disadvantages: without
significant work, it won't find sophisticated domain-specific issues.

\section*{How Address Sanitizer Works}
It's good to know how the tools that you use work. So, we'll look into
Address Sanitizer\footnote{More information: \url{https://llvm.org/devmtg/2011-11/Serebryany_FindingRacesMemoryErrors.pdf}}, which can be used with clang and gcc to provide
compile-time instrumentation using a small (5kLOC) library for
x86 and x86\_64 on Linux, Mac, and Windows. This tool has found
thousands of bugs in production code. Consider this
C function. 

\begin{lstlisting}[language=C]
  void foo() {
    int *x = malloc (10*sizeof(int));
    int *y = malloc (5*sizeof(int));

    y[0] = x[12];
  }
\end{lstlisting}
What happens when you call it?

Probably, in practice, you observe nothing weird. The array that \texttt{x}
points to might have extra bytes allocated at the end, or maybe
\texttt{x[12]} could happen to point to the memory allocated for
\texttt{x}, and the program continues to execute. \texttt{y[0]} gets
some value.

But this is undefined behaviour. You're not supposed to write this code,
per the C standard: you're not allowed to read past the end of the allocation.
C says that anything is allowed to happen after calling \texttt{foo()}.
Could be a crash, could be nothing, could get an arbitrary value for
\texttt{y[0]}.

Can we detect this undefined behaviour by writing a test case? I
wouldn't bet on it.

\paragraph{Demo.} From the Internet:
\begin{center}
  \url{https://github.com/dutor/asan-demo}
\end{center}

\paragraph{Instrumenting the code.} It's a compiler, right, so
it can generate whatever code it wants. Address Sanitizer generates
instrumented code at loads and stores, and tracks meta-information
about memory.

\begin{tabular}{ll}
 \begin{minipage}{.3\textwidth} \verb+*addr = e+ \end{minipage} & \begin{minipage}{.6\textwidth} \begin{lstlisting}[language=C]
if (IsPoisoned(addr))
  ReportError(addr, sz, true);
*addr = e;
    \end{lstlisting}
        \end{minipage}
\\ \hline
    \begin{minipage}{.3\textwidth} \verb+e = *addr+ \end{minipage} & \begin{minipage}{.6\textwidth} \begin{lstlisting}[language=C]
if (IsPoisoned(addr))
  ReportError(addr, sz, false);
e = *addr;
      \end{lstlisting}
    \end{minipage}
\end{tabular}

How do these functions work? How to make them fast?

\paragraph{Memory Layout.} We make two disjoint areas of memory:
\texttt{Mem} and \texttt{Shadow}. \texttt{Mem} is normal memory.
\texttt{Shadow} tracks meta-data about the memory; put information
about address \texttt{addr} in \texttt{Mem} at location
\texttt{MemToShadow(addr)} in \texttt{Shadow}. We need \texttt{MemToShadow}
to be a fast computation.

The shadow memory may then say that \texttt{addr} is normal memory,
or it may be poisoned in some way.

In a bit more detail, here's what an access could look like:
\begin{lstlisting}[language=C]
  shadow_addr = MemToShadow(addr);
  if (ShadowIsPoisoned(shadow_addr)) {
    ReportError(addr, sz, kIsWrite);
  }
\end{lstlisting}

You've seen the concept of memory alignment in ECE 222. For our purposes,
we'll assume that memory is allocated such that its address is always
divisible by 8 (QWORD-aligned). So, we can use one byte of \texttt{Shadow}
for one QWORD of \texttt{Mem}, to store the poisoning state of that byte.

There are a lot of poisoning states in the actual AddressSanitizer
implementation, but we'll talk about the simple case. Here are
the possibilities:
\begin{itemize}[noitemsep]
\item all 8 bytes are accessible (not poisoned); shadow value 0.
\item all 8 bytes are inaccessible (poisoned); shadow value $< 0$ (negative).
\item first $k$ bytes are accessible, the next $8-k$ bytes are not, where $0 < k < 8$; shadow value is $k$.
\end{itemize}
These possibilities are exhaustive due to allocations being aligned at
QWORD boundaries; that is, it's impossible that an allocation starts in the middle of a QWORD, or that there is something like $11001111$ where $1$ is accessible and $0$ is not. However, Address Sanitizer may store other metadata in addition to accessibility.

Let's look at some implementation:
\begin{lstlisting}[language=C]
  byte *shadow_addr = MemToShadow(addr);
  byte shadow_value = *shadow_addr;
  if (shadow_value < 0) { ReportError(addr, sz, kIsWrite); }
  else if (shadow_value) {
    if (SlowPathCheck(shadow_value, addr, sz)) {
      ReportError(addr, sz, kIsWrite);
    }
  }

  bool SlowPathCheck(shadow_value, addr, sz) {
    last_accessed_byte = (addr + sz - 1) % 8;
    return (last_accessed_byte >= shadow_value);
  }
\end{lstlisting}
Using bit magic, the compiler will automatically transform
\begin{lstlisting}[language=C,numbers=none]
      last_accessed_byte = (addr + sz - 1) % 8;
\end{lstlisting}
into
\begin{lstlisting}[language=C,numbers=none]
      last_accessed_byte = (addr & 7) +  (sz - 1)) & 7;
\end{lstlisting}
because bitwise AND is faster than modulo; convince yourself that
the transformation is correct.

OK, but what does \texttt{MemToShadow()} do? Here's a picture of
address space layout for a 32-bit process in Linux.

\begin{center}
  \includegraphics[width=.6\textwidth]{L07/process-address-space-layout.png}
\end{center}
There's room to put shadow memory in the middle there. In particular,
we can do this:
\begin{center}
  \includegraphics[width=.6\textwidth]{L07/shadow-memory-mapping.png}
\end{center}
It's then a quick calculation to convert a main-memory address to
the corresponding location in shadow memory, that is:
\begin{lstlisting}[language=C]
  byte *shadow_addr = addr >> 3 + 0x20000000;
  byte shadow_value = *shadow_addr;
  if (shadow_value < 0) { ReportError(addr, sz, kIsWrite); }
  else if (shadow_value) {
    if (SlowPathCheck(shadow_value, addr, sz)) {
      ReportError(addr, sz, kIsWrite);
    }
  }

  bool SlowPathCheck(shadow_value, addr, sz) {
    last_accessed_byte = ((addr & 7) + (sz - 1)) & 7;
    return (last_accessed_byte >= shadow_value);
  }
\end{lstlisting}
But remember our original example, with the allocation of 10 ints perhaps next to 5 ints.
The read from \texttt{x[12]} might go right into valid memory allocated for \texttt{y}.
One way is to remember the size of \texttt{x} and do a bounds check. But Address Sanitizerr
instead uses redzones around allocated memory. It's not perfect (you can overshoot), but it's faster.

Replace calls to \texttt{malloc()} by calls to \texttt{\_\_asan\_malloc()}. Here's a schematic implementation
of that function:
\begin{lstlisting}[language=C]
  void *__asan_malloc(size_t sz) {
    void *rz = malloc(RED_SZ);
    Poison(rz, RED_SZ);

    void *addr = malloc(sz); // assuming sequential allocation
    UnPoison(addr, sz);

    rz = malloc(RED_SZ);
    Poison(rz, RED_SZ);
    return addr;
  }
\end{lstlisting}
You can run a program compiled with Address Sanitizer that does an out-of-bounds
access and it'll show the memory as well as the redzones surrounding the memory.

\paragraph{The Stack.} OK, that works for heap allocations. Stack memory is not a result of
\texttt{malloc()} calls and can't be intercepted that way. But, we still can use the compiler to rewrite the code:
\begin{lstlisting}[language=C]
  void foo() {
    char redzone1[32];  // assuming QWORD alignment
    char a[8];          // another QWORD start
    char redzone2[24];
    char redzone3[32];  // third QWORD start
    int * shadow_base = MemToShadow(redzone1);
    shadow_base[0] = 0xffffffff; // poison redzone1
    shadow_base[1] = 0xffffff00; // poison redzone2 and unpoison 'a'
    shadow_base[2] = 0xffffffff; // poison redzone3

    // ...

    shadow_base[0] = shadow_base[1] = shadow_base[2] = 0; // unpoison all
    return;
  }
\end{lstlisting}

The slides also show x86 assembly from compiling these functions:
\begin{lstlisting}[language=C]
  long load8(long *a) { return *a; }
  int load4(int *a) { return *a; }
\end{lstlisting}
but I won't include that in these notes; use \url{godbolt.org} to see for yourself.

\paragraph{Other sanitizers.} It's not just AddressSanitizer. There are other dynamic analyses that
you can compile into your program.
\begin{itemize}[noitemsep]
\item ThreadSafetySanitizers: detect race conditions, i.e. accesses to the same memory by two threads where one access is a write, unprotected by a lock.
\item MemorySanitizer: detects uninitialized reads (at 3$\times$ slowdown); requires all code to be instrumented.
\item Undefined Behavior Sanitizer (ubsan): detects many types of undefined behaviour e.g. signed integer overflow, null pointer dereferences, etc.
\item DataFlowSanitizer: lets you write your own data-flow dynamic sanitizers
\item LeakSanitizer: detects memory leaks; no performance overhead.
\end{itemize}

\paragraph{Valgrind.} An alternatve to Address Sanitizer is Valgrind.
It is basically a just-in-time compiler from x86 to x86, and returns
more detailed information than asan, but runs more slowly. It does not
require compile-time instrumentation---it can just run code.
We said that Address Sanitizer marks up shadow memory. Valgrind instead
remembers the size of allocations and where they come from.
Running programs compiled with debug information yields better errors.

%% \section*{Links from the Fuzzing Book}

%% I didn't have time to incorporate this content this year, but it goes over similar content with more code.
%% \begin{itemize}[noitemsep]
%%   \item \url{https://www.fuzzingbook.org/html/MutationFuzzer.html}
%% \end{itemize}


\end{document}
